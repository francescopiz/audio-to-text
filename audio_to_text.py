#!/usr/bin/env python3
"""
Simple script to convert audio files to text using OpenAI's Whisper model.
Supports various audio formats including MP3, WAV, M4A, FLAC, etc.
"""

import os
import sys
import argparse
import warnings
import whisper
import signal
import json
from pathlib import Path
from datetime import datetime


# Global variable to track if process was interrupted
interrupted = False

def signal_handler(signum, frame):
    """Handle Ctrl+C interruption gracefully."""
    global interrupted
    print(f"\n\n‚ö†Ô∏è  Processo interrotto dall'utente (Ctrl+C)")
    print("üíæ Salvataggio del progresso parziale...")
    interrupted = True

def save_partial_progress(audio_file, model_size, partial_text, progress_file):
    """Save partial transcription progress."""
    progress_data = {
        "audio_file": audio_file,
        "model_size": model_size,
        "partial_text": partial_text,
        "timestamp": datetime.now().isoformat(),
        "status": "interrupted"
    }
    
    with open(progress_file, 'w', encoding='utf-8') as f:
        json.dump(progress_data, f, ensure_ascii=False, indent=2)
    
    print(f"üìÅ Progresso salvato in: {progress_file}")

def convert_audio_to_text(audio_file_path, model_size="base", output_file=None, save_progress=True):
    """
    Convert audio file to text using Whisper model with progress saving.
    
    Args:
        audio_file_path (str): Path to the audio file
        model_size (str): Whisper model size (tiny, base, small, medium, large)
        output_file (str): Optional output file path for the text
        save_progress (bool): Whether to save progress during transcription
    
    Returns:
        str: Transcribed text
    """
    global interrupted
    
    # Create progress file name
    base_name = Path(audio_file_path).stem
    progress_file = f"output/{base_name}_progress.json"
    
    try:
        # Check if audio file exists
        if not os.path.exists(audio_file_path):
            raise FileNotFoundError(f"Audio file not found: {audio_file_path}")
        
        print(f"Loading Whisper model '{model_size}'...")
        model = whisper.load_model(model_size)
        
        print(f"Transcribing audio file: {audio_file_path}")
        print("This may take a while depending on the audio length and model size...")
        print("üí° Premi Ctrl+C per interrompere (il progresso verr√† salvato automaticamente)")
        
        # Set up signal handler for graceful interruption
        signal.signal(signal.SIGINT, signal_handler)
        
        # Transcribe the audio
        result = model.transcribe(audio_file_path)
        
        # Check if process was interrupted
        if interrupted:
            partial_text = result.get("text", "")
            if save_progress and partial_text:
                save_partial_progress(audio_file_path, model_size, partial_text, progress_file)
            
            print(f"\nüìù Testo trascritto fino all'interruzione:")
            print("="*50)
            print(partial_text)
            print("="*50)
            return partial_text
        
        transcribed_text = result["text"]
        
        # Print the result
        print("\n" + "="*50)
        print("TRANSCRIPTION RESULT:")
        print("="*50)
        print(transcribed_text)
        print("="*50)
        
        # Save to file if output file is specified
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(transcribed_text)
            print(f"\nTranscription saved to: {output_file}")
        
        # Clean up progress file if transcription completed successfully
        if os.path.exists(progress_file):
            os.remove(progress_file)
            print("üßπ File di progresso rimosso (trascrizione completata)")
        
        return transcribed_text
        
    except KeyboardInterrupt:
        # Handle Ctrl+C explicitly - try to save whatever we have
        print(f"\n\n‚ö†Ô∏è  Processo interrotto dall'utente (Ctrl+C)")
        print("üíæ Tentativo di salvataggio del progresso...")
        
        # Try to get partial results if possible
        try:
            # This might not work if the model is in the middle of processing
            partial_text = "Trascrizione interrotta - nessun testo parziale disponibile"
            if save_progress:
                save_partial_progress(audio_file_path, model_size, partial_text, progress_file)
            print("üìÅ Progresso salvato (testo parziale non disponibile)")
        except:
            print("‚ùå Impossibile salvare il progresso parziale")
        
        return None
    except Exception as e:
        print(f"Error during transcription: {str(e)}")
        return None


def show_progress(progress_file):
    """Show saved progress from interrupted transcription."""
    try:
        if not os.path.exists(progress_file):
            print(f"‚ùå File di progresso non trovato: {progress_file}")
            return
        
        with open(progress_file, 'r', encoding='utf-8') as f:
            progress_data = json.load(f)
        
        print(f"\nüìä PROGRESSO SALVATO:")
        print("="*50)
        print(f"File audio: {progress_data['audio_file']}")
        print(f"Modello: {progress_data['model_size']}")
        print(f"Timestamp: {progress_data['timestamp']}")
        print(f"Status: {progress_data['status']}")
        print("\nüìù Testo trascritto:")
        print("-" * 30)
        print(progress_data['partial_text'])
        print("-" * 30)
        
    except Exception as e:
        print(f"‚ùå Errore nel leggere il progresso: {str(e)}")

def main():
    """Main function to handle command line arguments and run transcription."""
    parser = argparse.ArgumentParser(
        description="Convert audio files to text using OpenAI's Whisper model",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python audio_to_text.py audio.mp3
  python audio_to_text.py audio.wav --model large
  python audio_to_text.py audio.m4a --output transcription.txt
  python audio_to_text.py audio.mp3 --model small --output result.txt
  python audio_to_text.py --show-progress output/audio_progress.json
        """
    )
    
    parser.add_argument(
        "audio_file",
        nargs='?',
        help="Path to the audio file to transcribe"
    )
    
    parser.add_argument(
        "--model", "-m",
        choices=["tiny", "base", "small", "medium", "large"],
        default="base",
        help="Whisper model size (default: base). Larger models are more accurate but slower."
    )
    
    parser.add_argument(
        "--output", "-o",
        help="Output file path to save the transcription (optional)"
    )
    
    parser.add_argument(
        "--show-progress",
        help="Show saved progress from interrupted transcription"
    )
    
    args = parser.parse_args()
    
    # Handle show progress option
    if args.show_progress:
        show_progress(args.show_progress)
        return
    
    # Check if audio file is provided
    if not args.audio_file:
        parser.error("audio_file is required unless using --show-progress")
    
    # Convert audio to text
    result = convert_audio_to_text(args.audio_file, args.model, args.output)
    
    if result is None:
        sys.exit(1)
    else:
        print("\nTranscription completed successfully!")


if __name__ == "__main__":
    main()
